Hello guys, our project is based on theme interactive storytelling.
The objective of the project is to generate a complete story with images based on a brief description of the story provided by a user.
For story and image generation we're using large language and image generation models. For image generation we're using open source stable diffusion model from hugging face. For text generation we're using openai gpt-3.5-turbo.
The challgenge encountered while generating a images of the story is preserving the coherence of the images. Suppose we're giving a prompt to the stable diffusion model to generate a image of a man. It'll give of the image of a man with certain traits and structure. If we again ask for generation of image of a man, it'll generate a image of man with different dress and different traits. But during the story we don't want the traits of the important characters of the story to change. To address this issue, we're using image to image stable diffusion model, where we'll give base image as input to the model along with prompt on how to transform the base image. The stable diffusion will use the base and transform it according to the prompt. In this case we can preserve the colors used in the story. We have multiple base images for different scenarios, like village, city, sea, space. When a scene in the story is happening at a city, we'll use the base image of the city. Now for a scenario the colors in the story will remain preserved. Using this method we can' achieve coherence in the image to a great extent.



This is the process flow diagram:

first of all a story is generated based on the input from the user. The story is then split into several paragraphs, each paragraph will describe a scene from the story. The max limit of words in a paragraph is 150. We're not cutting a sentence in between after 150 words. In case after adding a sentence to a paragraph the word limit exceeds then, this sentence goes to next paragraph. After split of the story, we're feeding each paragraph to gpt model which gives us the prompt by summarizing the paragraph to less than 77 words, because stable  diffusion cannot take more than 77 words as prompt. At the same time we're using gpt model to provide the background which is present in the paragraph like city, village, sea. After getting response from gpt, we're selecting the base image according to it. Finally both summarized prompt and the base image is fed to stable diffusion model which give us the transformed image for the story.


Let's now quickly open the notebook and see go through the code.


The notebook is present in intel developer cloud, almost all the python libraries are installed in it. Only library we've to install is openai

Now put your openai api key here. To generate open api key, first create open ai account, now in the api keys section, select create api keys. after creating the api key copy it because you can't copy it afterwards.

Now paset your api key here. Also make sure the directory where stable diffusion models are present is specified correctly.

these functions are written to handle text genration using gpt 3.5 turbo

this is class where we'll load the stable diffusion model and generate the images using promts

this function splits the story into multiple paragraphs this is the function where which will act as the main function and print the story generation interface.

Let me run it and show you.